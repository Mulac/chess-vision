\chapter{Methods}
\label{chapter2}

<Everything that comes under the `Methods' criterion in the mark scheme should be described in one, or possibly more than one, chapter(s).>

\section{Data Collection}
At the heart of any machine learning project is the data.  
It is as important, often more important, than the code and presents many interesting
challenges.  **Why is this?**
Discussed in the following sections are some of the challenges and decisions that were considered.

\subsection{Sensors}
The eminent challenge is acquiring data in the first place.  This is highly context 
dependant, but as vision is primarily focused on spatial awareness the discussion 
will be limited to the sensors that can measure it.

Sensor choice is an important choice for any robotics application as there are 
important tradeoffs, as with any engineering challenge, which must be considered.

**Outline some of the tradeoffs between spatial sensors**

One important distinction to make is the difference between training and inference.
Requirements at the time of training my differ significantly to the requirements at 
inference.  Processing power, energy supply and realtime operation are some
of the constraints that will have to be met when considering different sensors.

The sensor used throughout this project is the RealSense SR305 which is a RGB-D camera
using structured and coded light to determine depth, it functions best indoors or in a 
controlled lighting situation.  For the reasons outlined above the RGB camera stream is 
mainly relied upon but there will be some discussion and comparision of piece detection 
with the depth sensor.  

\subsection{Auto-Labelling}
A closely related challenge of acquiring the data is that of labelling it too.
It is widely known that neural networks scale with the number of examples \cite{}.  
This will be explicitly explored for Chess Vision in section 3.1.
This however poses the question about how do we get access to a lot of labelled data 
for chess.  **Some examples of other auto labelling techniques**
The overall approach I took...


\subsection{Dataset Versioning}
With all this data the next challenge becomes self evident.
It is concerned with the question: How do we manage all of this?
Some of the problems... and why you need versioning...
Transitioning from git lfs to aws s3.  Perhaps a quick mention of other solutions.
How the Game class solves some of these challenges for us.


\section{Model Training}
Due to how we are autolabelling and the process of finding the corners we can stick with simple
image recognition and find a network that gets us the best result.

\subsection{Architectures}
To start, a good baseline is found.  A good baseline is a simple model to understand and easy to get decent results with.
For classification, the pathological baseline could be a random model, which could easily be extended to be weighted by 
count of examples for each class in the training set.  [Add mathematical formulation for demonstration (multinomial)]

This is common practice in exploritory \cite{} machine learning as it keeps the research from getting lost, so that the transitions
made are always from a known and working state.  It becomes very easy to see if an experiment is not working and easy to go back.

Keeping to this strategy, the multilayer perceptron (MLP) or fully connected network \cite{} was the first neural network to be explored.
By starting with the MLP, all complexity from the network is stripped away so the more extraneous elements such as the training loop and 
evaluation metrics can be built and tested.  [perhaps mention purposeley overfitting]

Once the full training and evaluation structure is functional, new features can be incrementally added and architectures explored.

As mentioned in \nameref{research} convolution operations, and in particular differentiable convolutional operations have had monumental 
impact on the field of computer vision and so this was the first experiment.

Quite quickly, especially with a limited dataset, overfitting becomes a major problem to overcome and so many experiments were positioned To
solve this problem.  Pooling, dropout layers and skip connections are amoung some of these.

ConvNext https://arxiv.org/pdf/2201.03545.pdf

\subsubsection{Optimizer}
An important part of any neural network training loop is the optimiser and so we will explore the effect of swapping these out.

[put into results]
AdamW was found produce more attractive results from comparing SGD with/without momentum and Adam and AdamW \cite{}
Learning Rate, Weight Regularization.

\subsubsection{Batch Normalization}
https://arxiv.org/abs/1502.03167 and renorm for small batch sizes https://arxiv.org/abs/1702.03275

\subsubsection{Dropouts}
https://arxiv.org/abs/1207.0580 shouldn't be used after convolution layers \cite{} there has been some work https://arxiv.org/abs/1904.03392

Pooling and DropPaths

\subsection{Transfer Learning}
There appears to be a trend occuring in the deep learning space.  Some organisation spends millions training an impossibly large nerual network
and others more and more are using these models, often fine-tuning for their own use cases.  \cite{} uses these large models as fixed feature extractors.

This appraoch makes sense as it is inpractical to retrain huge nerual networks that take weeks, millions of dollars and wasteful amounts of energy
to train \cite{}.

In the case of CNNs we can see the features that kernals in the early layers learn \cite{} are often very simple shapes and will be common for all
computer vision tasks.  This will explored this further in the results section as we visualise kernals from both random initalised models and 
pretrained models.

\subsection{Augmentation}
Data augmentation is strategy every machine learning practioner wants to have in their aresonal.  It addresses the data problem, allows us to truly 
leverage the data we have and generalise our models further.  The MINST \cite{} dataset itself was created using data augmentation.
In the case of chess piece classification, the correct augmentations or transformations should be chosen.
Go onto list the transformations used and why.

\subsection{Experiment Tracking}
Express importance of experiment tracking.  Some of the solutions \cite{} and their tradeoffs.
Why guild was chosen and how it was used.


\section{Inference}

\subsection{The Realiable Approach}
As in \cite{} the most reliable way to implement infrence during play is for a user to input when a move
has been complete.
This is not ideal because...

\subsection{The Not-So-Reliable Approach}
What if the system constantly updates with each new frame?
Why this is what we want, but is not as important for finding board state.
Some of the challenges involved and how we overcame them.

\subsubsection{Detecting Motion}
Difference between 2 frames.
SIFT / SURF