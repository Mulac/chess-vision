\chapter{Results}
\label{chapter3}

<Results, evaluation (including user evaluation) {\em etc.} should be described in one or more chapters. See the `Results and Discussion' criterion in the mark scheme for the sorts of material that may be included here.>

\section{Model Evaluation}

\subsection{Board Identification}
Aruco vs Chessboard vs heatmap. 

Compare results of 5 examples.  Why chessboard \cite{} will struggle with peices on the board.
Breif intro to Aruco.  For capturing data Aruco is very reliable, but won't always be possible to add onto the board.
Why heatmap solution looks like the best appraoch in the realword with unknown environments.  \cite{}

Time comparision for the 3.  And compare accuracy of heatmap against aruco.

\subsection{Multitask Learning}
How does it compare?

\subsection{Piece Recognition}
Use top-1 and top-5 to measure performance of different models.
Will include basic evaluation.  What happens what you increase layers, use more data, data augmentation.
Include Recall / Specificity / Sensitivity

\subsection{Piece Detection}
A benefit of having the depth sensor is an easier way to detech piece presence.  
Fixed threshold vs clustering.  Adding a margin.  How we actually did it.
Using paried T-test to evaulate.

Using a neural network instead as an additional class with our piece recognition network.
Compare that two having a two stage network, the first for piece detection and the second for recognition.

\subsection{Deep Dive into CNNs}
Visualising convolutional layers to analyse effectiveness.

\section{Realtime Analysis}
Frames per second.  Problems.

\subsection{Trails}
table of end-to-end experiments

\section{Comparison to Existing Solutions}
Summaries how my solution compares to others.  Need a table?
